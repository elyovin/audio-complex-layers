{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка библиотек"
      ],
      "metadata": {
        "id": "nldPImNJdcSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import imageio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import wandb\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "from tqdm import tqdm\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = 10, 6\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Set custom layout for plotly\n",
        "pio.templates['custom'] = go.layout.Template(\n",
        "    layout= dict(\n",
        "        font=dict(size=15),\n",
        "        title=dict(\n",
        "            font=dict(size=25),\n",
        "            x=0.5\n",
        "        ),\n",
        "        bargap=0.1,\n",
        "        width=900,\n",
        "        height=500,\n",
        "        autosize=False\n",
        "    )\n",
        ")\n",
        "pio.templates.default = 'plotly+custom'\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "XBfLuhqKduEE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "oi9dw23DdnQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "sripaadsrinivasan_audio_mnist_path = kagglehub.dataset_download('sripaadsrinivasan/audio-mnist')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he78hpzjdorf",
        "outputId": "efa72667-1fc3-42d9-f597-77b63e9e7dad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/sripaadsrinivasan/audio-mnist?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 948M/948M [00:09<00:00, 103MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sripaadsrinivasan_audio_mnist_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gtMk2ZvDdrGv",
        "outputId": "f0541019-d0aa-41f3-9677-4625fc3587ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/sripaadsrinivasan/audio-mnist/versions/1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# root = '/kaggle/input/audio-mnist/data'\n",
        "root = '/root/.cache/kagglehub/datasets/sripaadsrinivasan/audio-mnist/versions/1/data'\n",
        "n = 60\n",
        "folders = [os.path.join(root, str(i).zfill(2)) for i in range(1, n+1)]\n",
        "\n",
        "files = []\n",
        "for folder in folders:\n",
        "    files += os.listdir(folder)"
      ],
      "metadata": {
        "id": "TbYTPsPbe_0Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "for file in files:\n",
        "    label = file.split(\"_\")[0]\n",
        "    human = file.split(\"_\")[1]\n",
        "    X.append(os.path.join(root,human,file))\n",
        "    Y.append(label)"
      ],
      "metadata": {
        "id": "wpt0DRnBfBSv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MONxOkaMfCue",
        "outputId": "221c6072-65e2-46bf-c5c5-7a901bfc4304"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 30000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка функций"
      ],
      "metadata": {
        "id": "zXF7CE0od_5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoEPdg2XrRCq",
        "outputId": "50da5af6-31b2-4086-ef2d-a674a4f64258"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pairwise_distances(\n",
        "        all_features: np.ndarray,\n",
        "        all_labels: np.ndarray,\n",
        "        num_classes: int,\n",
        "        device: str = 'cuda',\n",
        "        metric: str = 'cosine'  # <- теперь явно используется евклидово расстояние\n",
        "    ):\n",
        "    model.eval()\n",
        "    if not torch.cuda.is_available():\n",
        "        model.to('cpu')\n",
        "    else:\n",
        "        model.to(device)\n",
        "\n",
        "    # Межклассовые расстояния\n",
        "    inter_class_dist_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            if i == j:\n",
        "                inter_class_dist_matrix[i, j] = 0\n",
        "            else:\n",
        "                feats_i = all_features[all_labels == i]\n",
        "                feats_j = all_features[all_labels == j]\n",
        "\n",
        "                if len(feats_i) > 0 and len(feats_j) > 0:\n",
        "                    dist = pairwise_distances(\n",
        "                        feats_i,\n",
        "                        feats_j,\n",
        "                        metric=metric\n",
        "                    ).mean()\n",
        "                    inter_class_dist_matrix[i, j] = dist\n",
        "                else:\n",
        "                    inter_class_dist_matrix[i, j] = np.nan\n",
        "\n",
        "    # Внутриклассовые расстояния\n",
        "    intra_class_distances = np.zeros(num_classes)\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        feats_i = all_features[all_labels == i]\n",
        "        if len(feats_i) > 1:\n",
        "            dists = pairwise_distances(feats_i, metric=metric)\n",
        "            intra_class_distances[i] = dists[np.triu_indices(len(feats_i), k=1)].mean()\n",
        "        else:\n",
        "            intra_class_distances[i] = np.nan\n",
        "\n",
        "    return inter_class_dist_matrix, intra_class_distances"
      ],
      "metadata": {
        "id": "fcgOJqhTrJDy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioMNISTDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            X: list[any],\n",
        "            Y: list[any],\n",
        "            target_sr: int = 16000\n",
        "            ) -> None:\n",
        "        self.audio = X\n",
        "        self.labels = Y\n",
        "        self.target_sr = target_sr\n",
        "        assert len(self.audio) == len(self.labels)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.audio)\n",
        "\n",
        "    def get_data(self, file: str) -> np.ndarray:\n",
        "        data, sr = librosa.load(file, sr=None)\n",
        "        data = librosa.resample(data, orig_sr=sr, target_sr=self.target_sr)\n",
        "        data = librosa.util.fix_length(data, size=12000)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        sample = self.audio[idx]\n",
        "        sample = self.get_data(sample)\n",
        "        sample = torch.tensor(sample, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        label = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "\n",
        "        return sample, label"
      ],
      "metadata": {
        "id": "6rf_-9fEeBQd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sJMiEcCibu7m"
      },
      "outputs": [],
      "source": [
        "class NonComplex(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        # Feature extraction layers\n",
        "        self.conv_layer1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm1d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=5, stride=3)\n",
        "        )\n",
        "        self.conv_layer2 = nn.Sequential(\n",
        "            nn.Conv1d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv_layer3 = nn.Sequential(\n",
        "            nn.Conv1d(256, 384, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(384),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv_layer4 = nn.Sequential(\n",
        "            nn.Conv1d(384, 384, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(384),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv_layer5 = nn.Sequential(\n",
        "            nn.Conv1d(384, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=5, stride=3)\n",
        "        )\n",
        "\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv_layer1,\n",
        "            self.conv_layer2,\n",
        "            self.conv_layer3,\n",
        "            self.conv_layer4,\n",
        "            self.conv_layer5,\n",
        "        )\n",
        "\n",
        "        # Linear layers\n",
        "        linear_layer_size: int = 4096\n",
        "        scaling_factor: int = 1\n",
        "        # scaling_factor: int = 1.7\n",
        "\n",
        "        self.linear_fc1 = nn.Sequential(\n",
        "            nn.Linear(5120, int(linear_layer_size * scaling_factor)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear_fc2 = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                int(linear_layer_size * scaling_factor),\n",
        "                int(linear_layer_size * scaling_factor) // 2\n",
        "            ),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear_fc3 = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                int(linear_layer_size * scaling_factor) // 2,\n",
        "                5120,\n",
        "            ),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.linears = nn.Sequential(\n",
        "            self.linear_fc1,\n",
        "            self.linear_fc2,\n",
        "            self.linear_fc3,\n",
        "        )\n",
        "\n",
        "        # Classification head layer\n",
        "        self.classification_head = nn.Linear(\n",
        "            5120,\n",
        "            TrainConfig.n_labels\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            x: torch.Tensor,\n",
        "            ) -> tuple[torch.Tensor, ...]:\n",
        "\n",
        "        out = self.convs(x)  # convlutions\n",
        "        out_after_conv = out.reshape(\n",
        "            out.size(0),\n",
        "            -1\n",
        "        )  # flatten\n",
        "\n",
        "\n",
        "        out_after_linear = self.linears(out_after_conv)  # backbone\n",
        "\n",
        "        \"\"\" LOG \"\"\"\n",
        "        out_after_linear_log = out_after_linear.detach().clone()\n",
        "        \"\"\" LOG \"\"\"\n",
        "\n",
        "        out_final = self.classification_head(out_after_linear)  # cls head\n",
        "\n",
        "        result = (\n",
        "            out_final,\n",
        "            out_after_linear_log\n",
        "        )\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device,\n",
        "        print_interval: int = 50,\n",
        "        log: bool = True\n",
        "        ) -> float:\n",
        "    total_loss: float = 0\n",
        "    correct_predictions: int = 0\n",
        "    total_samples: int = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    tqdm_loader = tqdm(train_dataloader, initial=1, desc='Training')\n",
        "    for iteration, (audio, label) in enumerate(tqdm_loader, start=1):\n",
        "        audio = audio.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds, _ = model(audio)\n",
        "        loss = criterion(preds, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if log and iteration != 0 and iteration % print_interval == 0:\n",
        "            audio, label = BALANCED_SAMPLE\n",
        "            audio = audio.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                preds, *output_logs = model(audio)\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            current_loss = total_loss / iteration\n",
        "            wandb.log({'avg_batch_loss': current_loss})  # logging\n",
        "            print(f\"\\nIteration {iteration}, Average Loss: {current_loss}\")\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "CWXrRZ4AerxS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(\n",
        "        model,\n",
        "        dataloader,\n",
        "        criterion,\n",
        "        device,\n",
        "        phase: str = 'Testing',\n",
        "        log: bool = True\n",
        "        ) -> tuple[any, ...]:\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    nn_logs: dict[int, list[np.ndarray]] = defaultdict(list)  # save nn output logs\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for audio, label in tqdm(dataloader, desc=phase):\n",
        "            audio = audio.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            preds, *output_logs = model(audio)\n",
        "            loss = criterion(preds, label)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            for i, output_log in enumerate(output_logs, start=1):\n",
        "                output_log = output_log.cpu().numpy()\n",
        "                nn_logs[i].extend(output_log)\n",
        "\n",
        "            _, predicted_labels = torch.max(preds, 1)\n",
        "            correct_predictions += (predicted_labels == label).sum().item()\n",
        "            total_samples += label.size(0)\n",
        "\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "            all_preds.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        'avg_loss': total_loss / len(dataloader),\n",
        "        'accuracy_top1': correct_predictions / total_samples,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro\n",
        "    }\n",
        "\n",
        "    if log:\n",
        "        print(f\"\\nEvaluation Results: Average Loss: {metrics['avg_loss']}, Accuracy: {metrics['accuracy_top1']:.4f}, \"\n",
        "              f\"F1-Micro: {metrics['f1_micro']:.4f}, F1-Macro: {metrics['f1_macro']:.4f}\")\n",
        "\n",
        "    return metrics, nn_logs, all_labels"
      ],
      "metadata": {
        "id": "pBqDOco8-ncK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загружаем доп. функции"
      ],
      "metadata": {
        "id": "ypIv-54ue2Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_params_count(model: nn.Module) -> tuple[int, int]:\n",
        "    all_params_count = sum(p.numel() for p in model.parameters())\n",
        "    requires_grad_params_count = sum(\n",
        "        p.numel() for p in model.parameters() if p.requires_grad\n",
        "    )\n",
        "\n",
        "    return all_params_count, requires_grad_params_count"
      ],
      "metadata": {
        "id": "1QvV1yZce325"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dtype(model: nn.Module) -> str:\n",
        "    param_dtype = str(next(model.parameters()).dtype)\n",
        "\n",
        "    return param_dtype"
      ],
      "metadata": {
        "id": "-D12bDS2e5r5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int) -> None:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "metadata": {
        "id": "6uomSZQHe7LL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42\n",
        "set_seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "zwFyAFW3e8pt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Конфиг"
      ],
      "metadata": {
        "id": "drjcEGLLfUDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TrainConfig:\n",
        "    n_epochs: int = 5\n",
        "    lr: float = 5e-5\n",
        "    batch_size: int = 64\n",
        "    momentum: float = 0.9\n",
        "\n",
        "    n_labels: int = 10\n",
        "    dataset: str = 'AudioMNIST'\n",
        "    train_size: float = 0.8\n",
        "    optimizer: str = 'Adam'\n",
        "\n",
        "\n",
        "config = TrainConfig()"
      ],
      "metadata": {
        "id": "YuPyKYYrfU9n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO5P-03ACm-h",
        "outputId": "fa01f893-6763-4b8f-f511-7b4a7b5e5a92"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_epochs': 5,\n",
              " 'lr': 5e-05,\n",
              " 'batch_size': 64,\n",
              " 'momentum': 0.9,\n",
              " 'n_labels': 10,\n",
              " 'dataset': 'AudioMNIST',\n",
              " 'train_size': 0.8,\n",
              " 'optimizer': 'Adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    entity='aelyovin',\n",
        "    project=config.dataset,\n",
        "    name=f'non_complex_bs_{config.batch_size}_lr_{config.lr}',\n",
        "    config=config.__dict__\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "13RrX4WbwfDF",
        "outputId": "684e9e1f-3f91-4a01-a27b-9f96a978a205"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melyovin\u001b[0m (\u001b[33maelyovin\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250708_145005-qffc3dv5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aelyovin/AudioMNIST/runs/qffc3dv5' target=\"_blank\">non_complex_bs_64_lr_5e-05</a></strong> to <a href='https://wandb.ai/aelyovin/AudioMNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aelyovin/AudioMNIST' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aelyovin/AudioMNIST/runs/qffc3dv5' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST/runs/qffc3dv5</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "75m1aXXLfXMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    train_size=config.train_size,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=Y,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_val,\n",
        "    y_val,\n",
        "    test_size=0.5,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_val,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "T24ncfbYfZd0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(X_val), len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfweUE6gfcPc",
        "outputId": "b63933fb-d7ad-46cc-8019-76ef09e5ecdb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 3000 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_train).value_counts(dropna=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "qYZNZ-YCffUc",
        "outputId": "bd8498f4-1a5a-4a60-96aa-6d038f041725"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    2400\n",
              "5    2400\n",
              "2    2400\n",
              "8    2400\n",
              "4    2400\n",
              "1    2400\n",
              "7    2400\n",
              "3    2400\n",
              "9    2400\n",
              "0    2400\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = AudioMNISTDataset(X_train, y_train)\n",
        "val_dataset = AudioMNISTDataset(X_val, y_val)\n",
        "test_dataset = AudioMNISTDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "NF5MxrFGfhRq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=TrainConfig.batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=TrainConfig.batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=TrainConfig.batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "id": "yXPVQtkXfirq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(train_loader)\n",
        "audio, label = next(it)"
      ],
      "metadata": {
        "id": "EJ9vT7jifkjj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio.shape, label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJnvLSAnfmDL",
        "outputId": "d2a811f9-5c7b-4e73-9a43-10022aaa05dc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 12000]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balanced_batch(\n",
        "        dataset,\n",
        "        n_samples_per_class: int = 30,\n",
        "        n_digits: int = 10  # digits 0-9\n",
        "        ) -> tuple[torch.Tensor, ...]:\n",
        "    # Group indices by label\n",
        "    label_to_indices = {}\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        label = label.item()\n",
        "        if label not in label_to_indices:\n",
        "            label_to_indices[label] = []\n",
        "        label_to_indices[label].append(idx)\n",
        "\n",
        "    # Select samples\n",
        "    selected_indices = []\n",
        "    for label in range(n_digits):\n",
        "        indices = label_to_indices[label]\n",
        "        selected = np.random.choice(indices, n_samples_per_class, replace=False)\n",
        "        selected_indices.extend(selected)\n",
        "\n",
        "    # Shuffle the order\n",
        "    np.random.shuffle(selected_indices)\n",
        "\n",
        "    # Create a subset dataset\n",
        "    subset = torch.utils.data.Subset(dataset, selected_indices)\n",
        "    loader = DataLoader(\n",
        "        subset,\n",
        "        batch_size=n_samples_per_class * n_digits,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return loader, next(iter(loader))"
      ],
      "metadata": {
        "id": "srVJ4cRelM1s"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BALANCED_LOADER, BALANCED_SAMPLE = get_balanced_batch(\n",
        "    test_dataset,\n",
        "    n_samples_per_class=30\n",
        ")"
      ],
      "metadata": {
        "id": "w5WIsQhBlXHO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BALANCED_SAMPLE[1].unique(return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZQvHWYlBeg7",
        "outputId": "067a2b98-70be-4b88-c293-927e7c9aef2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение"
      ],
      "metadata": {
        "id": "hd96--sm3ocC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NonComplex()"
      ],
      "metadata": {
        "id": "uh_TnvQmGjUt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_model_params_count(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVtRV2-qN7WW",
        "outputId": "d15f2bb3-3d91-4b7e-cd78-ed533b84cd2a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41068618, 41068618)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_dtype(model)"
      ],
      "metadata": {
        "id": "hf6l16JqftHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b5e3d084-bbc6-4fa0-f53f-6e09ff08b2a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.float32'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01CtK2MafuhV",
        "outputId": "0c868e69-1e75-47a6-a356-bc26eb4e43ab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=TrainConfig.lr\n",
        ")"
      ],
      "metadata": {
        "id": "8DrMkbDXfv9S"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6cKW2a4zbR9",
        "outputId": "8a7c46b8-db64-4ccc-c941-6ca5e72022c8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics, start_nn_val_logs, start_labels = evaluate_model(\n",
        "    model,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    device,\n",
        "    phase='Evaluating'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mspmJiGh0Azg",
        "outputId": "2fcfb11d-6991-4fb5-eff0-e596309f199b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 47/47 [00:04<00:00, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 2.3026209080472904, Accuracy: 0.1000, F1-Micro: 0.1000, F1-Macro: 0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_logs: dict[int, dict[str, float]] = dict()\n",
        "\n",
        "\n",
        "for epoch in range(1, TrainConfig.n_epochs + 1):\n",
        "    print(f'\\nEpoch {epoch}')\n",
        "    total_loss = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device,\n",
        "        print_interval=25\n",
        "    )\n",
        "\n",
        "    val_metrics, nn_val_logs, labels = evaluate_model(\n",
        "        model,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        device,\n",
        "        phase='Evaluating'\n",
        "    )\n",
        "\n",
        "    inter_matrix, intra_matrix = compute_pairwise_distances(\n",
        "        np.array(nn_val_logs[1]),\n",
        "        np.array(labels),\n",
        "        10\n",
        "    )\n",
        "\n",
        "    rename_map = {key: key + '_val' for key in val_metrics.keys()}\n",
        "    val_metrics = {rename_map.get(k, k): v for k, v in val_metrics.items()}\n",
        "\n",
        "    epoch_metrics = {\n",
        "        'avg_loss_train': total_loss / len(train_loader),\n",
        "        'mean_intra_distance_val': np.nanmean(intra_matrix),\n",
        "        'mean_inter_distance_val': np.nanmean(inter_matrix[inter_matrix != 0])\n",
        "\n",
        "    }\n",
        "    epoch_metrics.update(val_metrics)\n",
        "    wandb.log(epoch_metrics)\n",
        "\n",
        "    dist_matrices = {\n",
        "        'inter': inter_matrix,\n",
        "        'intra': intra_matrix\n",
        "    }\n",
        "    epoch_metrics.update(dist_matrices)\n",
        "\n",
        "    # Save model and metrics\n",
        "    torch.save(model.state_dict(), 'best_model.pth')\n",
        "    metrics_logs[epoch] = epoch_metrics\n",
        "\n",
        "\n",
        "    # Drop if overfitting\n",
        "    if epoch != 1 and metrics_logs[epoch]['avg_loss_val'] > metrics_logs[epoch - 1]['avg_loss_val']:\n",
        "        model = NonComplex()\n",
        "        model.load_state_dict(torch.load('best_model.pth'))\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgCAeI-fxoK",
        "outputId": "ca205ec8-b0fd-4f19-c867-e194a49b7191"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   7%|▋         | 27/375 [00:05<01:09,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 25, Average Loss: 0.0347860346082598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  14%|█▎        | 51/375 [00:10<01:30,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 50, Average Loss: 0.03196282498305664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  21%|██        | 77/375 [00:15<00:43,  6.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 75, Average Loss: 0.029474498943115275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  27%|██▋       | 102/375 [00:19<00:40,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 100, Average Loss: 0.03169773595873267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  34%|███▍      | 127/375 [00:22<00:35,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 125, Average Loss: 0.033411014940589664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  41%|████      | 152/375 [00:26<00:33,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 150, Average Loss: 0.03653981428748618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  47%|████▋     | 177/375 [00:30<00:38,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 175, Average Loss: 0.040188176783600024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  54%|█████▍    | 202/375 [00:34<00:24,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 200, Average Loss: 0.03949303254368715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  61%|██████    | 227/375 [00:38<00:24,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 225, Average Loss: 0.03838199241604242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  67%|██████▋   | 252/375 [00:42<00:17,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 250, Average Loss: 0.03700064490828663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  74%|███████▍  | 277/375 [00:45<00:14,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 275, Average Loss: 0.03565082320096818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  81%|████████  | 302/375 [00:48<00:10,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 300, Average Loss: 0.03456438138557132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  87%|████████▋ | 327/375 [00:52<00:07,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 325, Average Loss: 0.035066497823617496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  94%|█████████▍| 352/375 [00:56<00:03,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 350, Average Loss: 0.0366890471739628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 376it [00:59,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 375, Average Loss: 0.037124391455358514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 47/47 [00:03<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.0363028721061555, Accuracy: 0.9893, F1-Micro: 0.9893, F1-Macro: 0.9893\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   7%|▋         | 27/375 [00:03<00:50,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 25, Average Loss: 0.016815309459343553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  14%|█▍        | 52/375 [00:07<00:45,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 50, Average Loss: 0.017876365871634336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  21%|██        | 77/375 [00:10<00:48,  6.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 75, Average Loss: 0.01605904573497052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  27%|██▋       | 102/375 [00:15<00:45,  6.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 100, Average Loss: 0.01388435528584523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  34%|███▍      | 127/375 [00:18<00:35,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 125, Average Loss: 0.014095159208169207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  41%|████      | 152/375 [00:22<00:35,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 150, Average Loss: 0.015180948782896546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  47%|████▋     | 177/375 [00:25<00:28,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 175, Average Loss: 0.01621840330368806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  54%|█████▍    | 202/375 [00:29<00:24,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 200, Average Loss: 0.017228145607477926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  61%|██████    | 227/375 [00:32<00:21,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 225, Average Loss: 0.016810567725753775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  67%|██████▋   | 252/375 [00:36<00:20,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 250, Average Loss: 0.016638294565113027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  74%|███████▍  | 277/375 [00:39<00:14,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 275, Average Loss: 0.016157102636775975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  81%|████████  | 302/375 [00:43<00:10,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 300, Average Loss: 0.015339950820465067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  87%|████████▋ | 327/375 [00:46<00:07,  6.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 325, Average Loss: 0.015735996958123555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  94%|█████████▍| 352/375 [00:50<00:03,  6.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 350, Average Loss: 0.015885937877901598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 376it [00:53,  6.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 375, Average Loss: 0.016175812961009797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 47/47 [00:03<00:00, 14.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.8312321698411982, Accuracy: 0.8333, F1-Micro: 0.8333, F1-Macro: 0.8228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестовые метрики"
      ],
      "metadata": {
        "id": "-xr2DdWS7ALC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device);"
      ],
      "metadata": {
        "id": "Xi27M5VVj0KL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics, nn_test_logs, test_labels = evaluate_model(\n",
        "    model,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    device,\n",
        "    phase='Testing',\n",
        ")\n",
        "test_metrics = {key + '_test': val for key, val in test_metrics.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaJ2MVYt6cNE",
        "outputId": "0bebfccc-520d-4253-8db2-da4b342939be"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 47/47 [00:08<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.8599820105319328, Accuracy: 0.8297, F1-Micro: 0.8297, F1-Macro: 0.8218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuajABoJ7K1B",
        "outputId": "7a19e3d6-fa67-4c59-d38a-abceb947d79f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_loss_test': 0.8599820105319328,\n",
              " 'accuracy_top1_test': 0.8296666666666667,\n",
              " 'f1_micro_test': 0.8296666666666667,\n",
              " 'f1_macro_test': 0.8218390890308163}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inter_matrix, intra_matrix = compute_pairwise_distances(\n",
        "    np.array(nn_test_logs[1]),\n",
        "    np.array(test_labels),\n",
        "    10\n",
        ")\n",
        "dist_metrics = {\n",
        "    'mean_intra_distance_test': float(np.nanmean(intra_matrix)),\n",
        "    'mean_inter_distance_test': float(np.nanmean(inter_matrix[inter_matrix != 0]))\n",
        "}"
      ],
      "metadata": {
        "id": "oT7yyiXosh6t"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics.update(dist_metrics)"
      ],
      "metadata": {
        "id": "T1K3IA7Lsko2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics"
      ],
      "metadata": {
        "id": "mXqQMrsrslBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc21ab8-d972-4452-cc0e-c76f7ecf0d94"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_loss_test': 0.8599820105319328,\n",
              " 'accuracy_top1_test': 0.8296666666666667,\n",
              " 'f1_micro_test': 0.8296666666666667,\n",
              " 'f1_macro_test': 0.8218390890308163,\n",
              " 'mean_intra_distance_test': 0.07517625112086535,\n",
              " 'mean_inter_distance_test': 0.44879992273118763}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log(test_metrics)"
      ],
      "metadata": {
        "id": "bI1FJsXej73Y"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "N9IFQ-eb7yVV",
        "outputId": "25c6f845-93c0-46ae-ead1-91f6b150360c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_top1_test</td><td>▁</td></tr><tr><td>accuracy_top1_val</td><td>▇▆█▁</td></tr><tr><td>avg_batch_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>avg_loss_test</td><td>▁</td></tr><tr><td>avg_loss_train</td><td>█▂▁▁</td></tr><tr><td>avg_loss_val</td><td>▂▂▁█</td></tr><tr><td>f1_macro_test</td><td>▁</td></tr><tr><td>f1_macro_val</td><td>▇▆█▁</td></tr><tr><td>f1_micro_test</td><td>▁</td></tr><tr><td>f1_micro_val</td><td>▇▆█▁</td></tr><tr><td>mean_inter_distance_test</td><td>▁</td></tr><tr><td>mean_inter_distance_val</td><td>▁▄█▃</td></tr><tr><td>mean_intra_distance_test</td><td>▁</td></tr><tr><td>mean_intra_distance_val</td><td>▄▄▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_top1_test</td><td>0.82967</td></tr><tr><td>accuracy_top1_val</td><td>0.83333</td></tr><tr><td>avg_batch_loss</td><td>0.01618</td></tr><tr><td>avg_loss_test</td><td>0.85998</td></tr><tr><td>avg_loss_train</td><td>0.01618</td></tr><tr><td>avg_loss_val</td><td>0.83123</td></tr><tr><td>f1_macro_test</td><td>0.82184</td></tr><tr><td>f1_macro_val</td><td>0.82278</td></tr><tr><td>f1_micro_test</td><td>0.82967</td></tr><tr><td>f1_micro_val</td><td>0.83333</td></tr><tr><td>mean_inter_distance_test</td><td>0.4488</td></tr><tr><td>mean_inter_distance_val</td><td>0.45016</td></tr><tr><td>mean_intra_distance_test</td><td>0.07518</td></tr><tr><td>mean_intra_distance_val</td><td>0.07373</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">non_complex_bs_64_lr_5e-05</strong> at: <a href='https://wandb.ai/aelyovin/AudioMNIST/runs/qffc3dv5' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST/runs/qffc3dv5</a><br> View project at: <a href='https://wandb.ai/aelyovin/AudioMNIST' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250708_145005-qffc3dv5/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}