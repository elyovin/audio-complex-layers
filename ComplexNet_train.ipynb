{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка библиотек"
      ],
      "metadata": {
        "id": "nldPImNJdcSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU complexPyTorch\n",
        "!pip install -U kaleido\n",
        "!pip install -dU umap"
      ],
      "metadata": {
        "id": "MnspXQSqSVTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78eb44c5-6d57-463c-b7fb-c74a6da3d891"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: choreographer>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from kaleido) (1.0.9)\n",
            "Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from kaleido) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.11/dist-packages (from kaleido) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kaleido) (24.2)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.11/dist-packages (from choreographer>=1.0.5->kaleido) (3.20.1)\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import imageio\n",
        "import kaleido\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import wandb\n",
        "import umap\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import complexPyTorch.complexLayers as cvnn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "from tqdm import tqdm\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = 10, 6\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Set custom layout for plotly\n",
        "pio.templates['custom'] = go.layout.Template(\n",
        "    layout= dict(\n",
        "        font=dict(size=15),\n",
        "        title=dict(\n",
        "            font=dict(size=25),\n",
        "            x=0.5\n",
        "        ),\n",
        "        bargap=0.1,\n",
        "        width=900,\n",
        "        height=500,\n",
        "        autosize=False\n",
        "    )\n",
        ")\n",
        "pio.templates.default = 'plotly+custom'\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "XBfLuhqKduEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb494a38-0420-4699-9a23-65faaf926b51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/kaleido/__init__.py:14: UserWarning: \n",
            "\n",
            "Warning: You have Plotly version 5.24.1, which is not compatible with this version of Kaleido (1.0.0).\n",
            "\n",
            "This means that static image generation (e.g. `fig.write_image()`) will not work.\n",
            "\n",
            "Please upgrade Plotly to version 6.1.1 or greater, or downgrade Kaleido to version 0.2.1.\n",
            "\n",
            "  from .kaleido import Kaleido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "oi9dw23DdnQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "sripaadsrinivasan_audio_mnist_path = kagglehub.dataset_download('sripaadsrinivasan/audio-mnist')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he78hpzjdorf",
        "outputId": "577102f1-b93f-4b70-c963-3da398797aa0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sripaadsrinivasan_audio_mnist_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gtMk2ZvDdrGv",
        "outputId": "8a05ae59-3fe7-4c3a-8abf-13600b83168a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/audio-mnist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/kaggle/input/audio-mnist/data'\n",
        "# root = '/root/.cache/kagglehub/datasets/sripaadsrinivasan/audio-mnist/versions/1/data'\n",
        "n = 60\n",
        "folders = [os.path.join(root,str(i).zfill(2)) for i in range(1,n+1)]\n",
        "\n",
        "files = []\n",
        "for folder in folders:\n",
        "    files += os.listdir(folder)"
      ],
      "metadata": {
        "id": "TbYTPsPbe_0Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "for file in files:\n",
        "    label = file.split(\"_\")[0]\n",
        "    human = file.split(\"_\")[1]\n",
        "    X.append(os.path.join(root,human,file))\n",
        "    Y.append(label)"
      ],
      "metadata": {
        "id": "wpt0DRnBfBSv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(Y)"
      ],
      "metadata": {
        "id": "MONxOkaMfCue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207bba0f-bd62-4fb4-b25c-edce47d05169"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 30000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка функций"
      ],
      "metadata": {
        "id": "zXF7CE0od_5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioMNISTDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            X: list[any],\n",
        "            Y: list[any],\n",
        "            target_sr: int = 16000\n",
        "            ) -> None:\n",
        "        self.audio = X\n",
        "        self.labels = Y\n",
        "        self.target_sr = target_sr\n",
        "        assert len(self.audio) == len(self.labels)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.audio)\n",
        "\n",
        "    def get_data(self, file: str) -> np.ndarray:\n",
        "        data, sr = librosa.load(file, sr=None)\n",
        "        data = librosa.resample(data, orig_sr=sr, target_sr=self.target_sr)\n",
        "        data = librosa.util.fix_length(data, size=12000)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        sample = self.audio[idx]\n",
        "        sample = self.get_data(sample)\n",
        "        sample = torch.tensor(sample, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        label = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "\n",
        "        return sample, label"
      ],
      "metadata": {
        "id": "6rf_-9fEeBQd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sJMiEcCibu7m"
      },
      "outputs": [],
      "source": [
        "class Complex(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        # Feature extraction layers\n",
        "        self.conv_layer1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm1d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=5, stride=3)\n",
        "        )\n",
        "        self.conv_layer2 = nn.Sequential(\n",
        "            nn.Conv1d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv_layer3 = nn.Sequential(\n",
        "            nn.Conv1d(256, 384, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(384),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv_layer4 = nn.Sequential(\n",
        "            nn.Conv1d(384, 384, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(384),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv_layer5 = nn.Sequential(\n",
        "            nn.Conv1d(384, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=5, stride=3)\n",
        "        )\n",
        "\n",
        "        self.convs = nn.Sequential(\n",
        "            self.conv_layer1,\n",
        "            self.conv_layer2,\n",
        "            self.conv_layer3,\n",
        "            self.conv_layer4,\n",
        "            self.conv_layer5,\n",
        "        )\n",
        "\n",
        "        # Linear layers\n",
        "        linear_layer_size: int = 4096\n",
        "\n",
        "        self.linear_fc1 = nn.Sequential(\n",
        "            cvnn.ComplexLinear(5120, linear_layer_size),\n",
        "            cvnn.ComplexReLU()\n",
        "        )\n",
        "        self.linear_fc2 = nn.Sequential(\n",
        "            cvnn.ComplexLinear(linear_layer_size, linear_layer_size // 2),\n",
        "            cvnn.ComplexReLU()\n",
        "        )\n",
        "        self.linear_fc3 = nn.Sequential(\n",
        "            cvnn.ComplexLinear(linear_layer_size // 2, linear_layer_size),\n",
        "            cvnn.ComplexReLU()\n",
        "        )\n",
        "\n",
        "        self.linears = nn.Sequential(\n",
        "            self.linear_fc1,\n",
        "            self.linear_fc2,\n",
        "            self.linear_fc3,\n",
        "        )\n",
        "\n",
        "        # Classification head layer\n",
        "        self.classification_head = nn.Linear(5120, TrainConfig.n_labels)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            x: torch.Tensor,\n",
        "            ) -> tuple[torch.Tensor, ...]:\n",
        "\n",
        "        out = self.convs(x)  # convlutions\n",
        "        out_after_conv = out.reshape(\n",
        "            out.size(0),\n",
        "            -1\n",
        "        )  # concatenate\n",
        "        n = out_after_conv.shape[-1]\n",
        "\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "        out_after_conv_log = out_after_conv.detach().clone()\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "\n",
        "        normalization_scale = 2 / n\n",
        "        out_complex = torch.fft.fft(\n",
        "            out_after_conv * normalization_scale,\n",
        "            dim=-1\n",
        "        )  # to complex\n",
        "\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "        out_complex_abs_before_linear_log = out_complex.detach().abs().clone()\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "\n",
        "        \"\"\" BACKBONE \"\"\"\n",
        "        out_complex = self.linears(out_complex)  # move through complex layers\n",
        "        \"\"\" BACKBONE \"\"\"\n",
        "\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "        out_complex_abs_after_linear_log = out_complex.detach().abs().clone()\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "\n",
        "        # Back to real\n",
        "        inverse_normalization_scale = n / 2\n",
        "        out_after_ifft = torch.fft.ifft(\n",
        "            out_complex * inverse_normalization_scale,\n",
        "            dim=-1,\n",
        "            n=n\n",
        "        )\n",
        "        out_after_ifft = torch.abs(out_after_ifft)\n",
        "\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "        out_after_ifft_log = out_after_ifft.detach().clone()\n",
        "        \"\"\" LOG FOR VISUALIZATION \"\"\"\n",
        "\n",
        "        out_final = self.classification_head(out_after_ifft)  # cls head\n",
        "\n",
        "        result = (\n",
        "            out_final,\n",
        "            out_after_conv_log,\n",
        "            out_complex_abs_before_linear_log,\n",
        "            out_complex_abs_after_linear_log,\n",
        "            out_after_ifft_log\n",
        "        )\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device,\n",
        "        print_interval: int = 50,\n",
        "        log: bool = True\n",
        "        ) -> tuple:\n",
        "    total_loss: float = 0\n",
        "    correct_predictions: int = 0\n",
        "    total_samples: int = 0\n",
        "\n",
        "    nn_logs: dict[int, list[np.ndarray]] = dict()  # save nn output logs\n",
        "\n",
        "    model.train()\n",
        "    tqdm_loader = tqdm(train_dataloader, initial=1, desc='Training')\n",
        "    for iteration, (audio, label) in enumerate(tqdm_loader, start=1):\n",
        "        audio = audio.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds, *_ = model(audio)\n",
        "        loss = criterion(preds, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if log and iteration != 0 and iteration % print_interval == 0:\n",
        "            audio, label = BALANCED_SAMPLE\n",
        "            audio = audio.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                preds, *output_logs = model(audio)\n",
        "\n",
        "            nn_logs[iteration]: dict[str, any] = dict()\n",
        "            nn_logs[iteration]['nn_output'] = [\n",
        "                *(output_log.cpu().numpy() for output_log in output_logs),\n",
        "                label.detach().clone().cpu().numpy()\n",
        "            ]\n",
        "            nn_logs[iteration]['metrics'] = evaluate_model(\n",
        "                model,\n",
        "                BALANCED_LOADER,\n",
        "                criterion,\n",
        "                device,\n",
        "                phase='Evaluationg batch',\n",
        "                log=False\n",
        "            )\n",
        "            model.train()\n",
        "\n",
        "            current_loss = total_loss / iteration\n",
        "            wandb.log({'avg_batch_loss': current_loss})  # logging\n",
        "            print(f\"\\nIteration {iteration}, Average Loss: {current_loss}\")\n",
        "\n",
        "    return total_loss, nn_logs"
      ],
      "metadata": {
        "id": "CWXrRZ4AerxS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(\n",
        "        model,\n",
        "        dataloader,\n",
        "        criterion,\n",
        "        device,\n",
        "        phase: str = 'Testing',\n",
        "        log: bool = True\n",
        "        ) -> tuple[any, ...]:\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "\n",
        "    nn_logs: dict[int, list[np.ndarray]] = defaultdict(list)  # save nn output logs\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for audio, label in tqdm(dataloader, desc=phase):\n",
        "            audio = audio.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            preds, *output_logs = model(audio)\n",
        "            loss = criterion(preds, label)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            for i, output_log in enumerate(output_logs, start=1):\n",
        "                output_log = output_log.cpu().numpy()\n",
        "                nn_logs[i].extend(output_log)\n",
        "\n",
        "            _, predicted_labels = torch.max(preds, 1)\n",
        "            correct_predictions += (predicted_labels == label).sum().item()\n",
        "            total_samples += label.size(0)\n",
        "\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "            all_preds.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        'avg_loss': total_loss / len(dataloader),\n",
        "        'accuracy_top1': correct_predictions / total_samples,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro\n",
        "    }\n",
        "\n",
        "    if log:\n",
        "        print(f\"\\nEvaluation Results: Average Loss: {metrics['avg_loss']}, Accuracy: {metrics['accuracy_top1']:.4f}, \"\n",
        "              f\"F1-Micro: {metrics['f1_micro']:.4f}, F1-Macro: {metrics['f1_macro']:.4f}\")\n",
        "\n",
        "    return metrics, nn_logs, all_labels"
      ],
      "metadata": {
        "id": "pBqDOco8-ncK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pairwise_distances(\n",
        "        all_features: np.ndarray,\n",
        "        all_labels: np.ndarray,\n",
        "        num_classes: int,\n",
        "        device: str = 'cuda',\n",
        "        metric: str = 'cosine'\n",
        "    ):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Межклассовые расстояния\n",
        "    inter_class_dist_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            if i == j:\n",
        "                inter_class_dist_matrix[i, j] = 0\n",
        "            else:\n",
        "                feats_i = all_features[all_labels == i]\n",
        "                feats_j = all_features[all_labels == j]\n",
        "\n",
        "                if len(feats_i) > 0 and len(feats_j) > 0:\n",
        "                    dist = pairwise_distances(\n",
        "                        feats_i,\n",
        "                        feats_j,\n",
        "                        metric=metric\n",
        "                    ).mean()\n",
        "                    inter_class_dist_matrix[i, j] = dist\n",
        "                else:\n",
        "                    inter_class_dist_matrix[i, j] = np.nan\n",
        "\n",
        "    # Внутриклассовые расстояния\n",
        "    intra_class_distances = np.zeros(num_classes)\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        feats_i = all_features[all_labels == i]\n",
        "        if len(feats_i) > 1:\n",
        "            dists = pairwise_distances(feats_i, metric=metric)\n",
        "            intra_class_distances[i] = dists[np.triu_indices(len(feats_i), k=1)].mean()\n",
        "        else:\n",
        "            intra_class_distances[i] = np.nan\n",
        "\n",
        "    return inter_class_dist_matrix, intra_class_distances"
      ],
      "metadata": {
        "id": "VpEkAKEQdBw-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загружаем доп. функции"
      ],
      "metadata": {
        "id": "ypIv-54ue2Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_params_count(model: nn.Module) -> tuple[int, int]:\n",
        "    all_params_count = sum(p.numel() for p in model.parameters())\n",
        "    requires_grad_params_count = sum(\n",
        "        p.numel() for p in model.parameters() if p.requires_grad\n",
        "    )\n",
        "\n",
        "    return all_params_count, requires_grad_params_count"
      ],
      "metadata": {
        "id": "1QvV1yZce325"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dtype(model: nn.Module) -> str:\n",
        "    param_dtype = str(next(model.parameters()).dtype)\n",
        "\n",
        "    return param_dtype"
      ],
      "metadata": {
        "id": "-D12bDS2e5r5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int) -> None:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "metadata": {
        "id": "6uomSZQHe7LL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42\n",
        "set_seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "zwFyAFW3e8pt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Конфиг"
      ],
      "metadata": {
        "id": "drjcEGLLfUDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TrainConfig:\n",
        "    n_epochs: int = 5\n",
        "    lr: float = 3e-5\n",
        "    batch_size: int = 128\n",
        "    momentum: float = 0.9\n",
        "\n",
        "    n_labels: int = 10\n",
        "    dataset: str = 'AudioMNIST'\n",
        "    train_size: float = 0.8\n",
        "    optimizer: str = 'Adam'\n",
        "\n",
        "\n",
        "config = TrainConfig()"
      ],
      "metadata": {
        "id": "YuPyKYYrfU9n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO5P-03ACm-h",
        "outputId": "7271e03f-6379-48e6-a363-88d7eb2a7866"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_epochs': 5,\n",
              " 'lr': 3e-05,\n",
              " 'batch_size': 128,\n",
              " 'momentum': 0.9,\n",
              " 'n_labels': 10,\n",
              " 'dataset': 'AudioMNIST',\n",
              " 'train_size': 0.8,\n",
              " 'optimizer': 'Adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    entity='aelyovin',\n",
        "    project=config.dataset,\n",
        "    name=f'complex_bs_{config.batch_size}_lr_{config.lr}',\n",
        "    config=config.__dict__\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "13RrX4WbwfDF",
        "outputId": "12b50655-82cc-496d-8e97-c02843ef9478"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melyovin\u001b[0m (\u001b[33maelyovin\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250708_154344-hcoumbfq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aelyovin/AudioMNIST/runs/hcoumbfq' target=\"_blank\">complex_bs_128_lr_3e-05</a></strong> to <a href='https://wandb.ai/aelyovin/AudioMNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aelyovin/AudioMNIST' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aelyovin/AudioMNIST/runs/hcoumbfq' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST/runs/hcoumbfq</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "75m1aXXLfXMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    train_size=config.train_size,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=Y,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_val,\n",
        "    y_val,\n",
        "    test_size=0.5,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_val,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "T24ncfbYfZd0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(X_val), len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfweUE6gfcPc",
        "outputId": "8bd32793-63ba-4a1a-d1bc-f38e132d0424"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 3000 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_train).value_counts(dropna=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "qYZNZ-YCffUc",
        "outputId": "458ba101-08e0-4014-ca83-4047545e914b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    2400\n",
              "5    2400\n",
              "2    2400\n",
              "8    2400\n",
              "4    2400\n",
              "1    2400\n",
              "7    2400\n",
              "3    2400\n",
              "9    2400\n",
              "0    2400\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = AudioMNISTDataset(X_train, y_train)\n",
        "val_dataset = AudioMNISTDataset(X_val, y_val)\n",
        "test_dataset = AudioMNISTDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "NF5MxrFGfhRq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=TrainConfig.batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=TrainConfig.batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=TrainConfig.batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "id": "yXPVQtkXfirq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(train_loader)\n",
        "audio, label = next(it)"
      ],
      "metadata": {
        "id": "EJ9vT7jifkjj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio.shape, label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJnvLSAnfmDL",
        "outputId": "b7ac02b3-84e4-4d3f-fc30-a9ff46d6be6d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 1, 12000]), torch.Size([128]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fDqYyCZOTix",
        "outputId": "e5f70a71-0a19-438a-a112-b3da86d672dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balanced_batch(\n",
        "        dataset,\n",
        "        n_samples_per_class: int = 30,\n",
        "        n_digits: int = 10  # digits 0-9\n",
        "        ) -> tuple[torch.Tensor, ...]:\n",
        "    # Group indices by label\n",
        "    label_to_indices = {}\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        label = label.item()\n",
        "        if label not in label_to_indices:\n",
        "            label_to_indices[label] = []\n",
        "        label_to_indices[label].append(idx)\n",
        "\n",
        "    # Select samples\n",
        "    selected_indices = []\n",
        "    for label in range(n_digits):\n",
        "        indices = label_to_indices[label]\n",
        "        selected = np.random.choice(indices, n_samples_per_class, replace=False)\n",
        "        selected_indices.extend(selected)\n",
        "\n",
        "    # Shuffle the order\n",
        "    np.random.shuffle(selected_indices)\n",
        "\n",
        "    # Create a subset dataset\n",
        "    subset = torch.utils.data.Subset(dataset, selected_indices)\n",
        "    loader = DataLoader(\n",
        "        subset,\n",
        "        batch_size=n_samples_per_class * n_digits,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return loader, next(iter(loader))"
      ],
      "metadata": {
        "id": "srVJ4cRelM1s"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BALANCED_LOADER, BALANCED_SAMPLE = get_balanced_batch(\n",
        "    test_dataset,\n",
        "    n_samples_per_class=30\n",
        ")"
      ],
      "metadata": {
        "id": "w5WIsQhBlXHO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BALANCED_SAMPLE[1].unique(return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZQvHWYlBeg7",
        "outputId": "02f97832-6d3c-46f4-f0c8-08f4de4d3b52"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение"
      ],
      "metadata": {
        "id": "hd96--sm3ocC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Complex()"
      ],
      "metadata": {
        "id": "uh_TnvQmGjUt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_model_params_count(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgInI6xGfrn5",
        "outputId": "5329bf14-599d-4419-e9e5-4202d2557e33"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76729418, 76729418)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_dtype(model)"
      ],
      "metadata": {
        "id": "hf6l16JqftHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "320fe10f-8b4b-401a-a411-316be4875fc7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.float32'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01CtK2MafuhV",
        "outputId": "efed6105-ef0b-4c19-d5a8-ee77cfecec3f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=TrainConfig.lr\n",
        ")"
      ],
      "metadata": {
        "id": "8DrMkbDXfv9S"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics, start_nn_val_logs, start_labels = evaluate_model(\n",
        "    model,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    device,\n",
        "    phase='Evaluating'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh3F3LDrMWLQ",
        "outputId": "848a6cfa-48f0-458f-dcda-b9455c247b32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 2.360150913397471, Accuracy: 0.1000, F1-Micro: 0.1000, F1-Macro: 0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_logs: dict[int, dict[str, float]] = dict()\n",
        "nn_logs: dict[int, dict[int, list[np.ndarray]]] = dict()\n",
        "nn_all_val_logs: dict[int, dict[int, list[np.ndarray]]] = dict()\n",
        "\n",
        "\n",
        "for epoch in range(1, TrainConfig.n_epochs + 1):\n",
        "    print(f'\\nEpoch {epoch}')\n",
        "    total_loss, epoch_nn_logs = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device,\n",
        "        print_interval=12\n",
        "    )\n",
        "\n",
        "    val_metrics, nn_val_logs, labels = evaluate_model(\n",
        "        model,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        device,\n",
        "        phase='Evaluating'\n",
        "    )\n",
        "\n",
        "    inter_matrix, intra_matrix = compute_pairwise_distances(\n",
        "        np.array(nn_val_logs[4]),\n",
        "        np.array(labels),\n",
        "        10\n",
        "    )\n",
        "\n",
        "    nn_all_val_logs[epoch] = nn_val_logs\n",
        "\n",
        "    epoch_metrics = {\n",
        "        'avg_loss_train': total_loss / len(train_loader),\n",
        "        'mean_intra_distance_val': np.nanmean(intra_matrix),\n",
        "        'mean_inter_distance_val': np.nanmean(inter_matrix[inter_matrix != 0])\n",
        "    }\n",
        "    rename_map = {key: key + '_val' for key in val_metrics.keys()}\n",
        "    val_metrics = {rename_map.get(k, k): v for k, v in val_metrics.items()}\n",
        "    epoch_metrics.update(val_metrics)\n",
        "\n",
        "    # Logging\n",
        "    wandb.log(epoch_metrics)\n",
        "    nn_logs[epoch] = epoch_nn_logs\n",
        "\n",
        "    # Save model and metrics\n",
        "    torch.save(model.state_dict(), 'best_model.pth')\n",
        "    metrics_logs[epoch] = epoch_metrics\n",
        "\n",
        "    # Drop if overfitting\n",
        "    if epoch != 1 and metrics_logs[epoch]['avg_loss_val'] > metrics_logs[epoch - 1]['avg_loss_val']:\n",
        "        model = Complex()\n",
        "        model.load_state_dict(torch.load('best_model.pth'))\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgCAeI-fxoK",
        "outputId": "7be0bb39-e968-4c87-d203-8e764a758096"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|▋         | 12/188 [00:12<03:25,  1.17s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
            "Training:   7%|▋         | 13/188 [00:14<04:10,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 12, Average Loss: 2.1350370248158774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 24/188 [00:26<03:02,  1.11s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "Training:  13%|█▎        | 25/188 [00:28<03:38,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 24, Average Loss: 1.9108574042717617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|█▉        | 36/188 [00:40<02:46,  1.09s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
            "Training:  20%|█▉        | 37/188 [00:42<03:18,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 36, Average Loss: 1.640454779068629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  26%|██▌       | 48/188 [00:54<02:31,  1.08s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
            "Training:  26%|██▌       | 49/188 [00:55<02:59,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 48, Average Loss: 1.389644316708048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|███▏      | 60/188 [01:08<02:41,  1.26s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
            "Training:  32%|███▏      | 61/188 [01:11<03:33,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 60, Average Loss: 1.2174542958537737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|███▊      | 72/188 [01:23<02:09,  1.12s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
            "Training:  39%|███▉      | 73/188 [01:25<02:31,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 72, Average Loss: 1.071340525522828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  45%|████▍     | 84/188 [01:37<01:56,  1.12s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  45%|████▌     | 85/188 [01:39<02:17,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 84, Average Loss: 0.9586449852656751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  51%|█████     | 96/188 [01:51<01:45,  1.15s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  52%|█████▏    | 97/188 [01:53<02:02,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 96, Average Loss: 0.8680172259919345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  57%|█████▋    | 108/188 [02:05<01:30,  1.13s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "Training:  58%|█████▊    | 109/188 [02:07<01:49,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 108, Average Loss: 0.7950135308007399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 120/188 [02:20<01:20,  1.18s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "Training:  64%|██████▍   | 121/188 [02:22<01:35,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 120, Average Loss: 0.7325438984359304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|███████   | 132/188 [02:35<01:06,  1.18s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
            "Training:  71%|███████   | 133/188 [02:37<01:20,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 132, Average Loss: 0.6806715620173649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  77%|███████▋  | 144/188 [02:49<00:47,  1.09s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "Training:  77%|███████▋  | 145/188 [02:51<00:56,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 144, Average Loss: 0.636732087781032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  83%|████████▎ | 156/188 [03:03<00:35,  1.10s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  84%|████████▎ | 157/188 [03:05<00:40,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 156, Average Loss: 0.5970531929379854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  89%|████████▉ | 168/188 [03:17<00:22,  1.11s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
            "Training:  90%|████████▉ | 169/188 [03:19<00:25,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 168, Average Loss: 0.5615845786274544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  96%|█████████▌| 180/188 [03:31<00:08,  1.09s/it]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "Training:  96%|█████████▋| 181/188 [03:33<00:09,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 180, Average Loss: 0.5321570574616392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 189it [03:41,  1.18s/it]\n",
            "Evaluating: 100%|██████████| 24/24 [00:08<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.11277652019634843, Accuracy: 0.9667, F1-Micro: 0.9667, F1-Macro: 0.9670\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|▋         | 12/188 [00:05<01:22,  2.14it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
            "Training:   7%|▋         | 13/188 [00:06<02:18,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 12, Average Loss: 0.11048245554169019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 24/188 [00:12<01:20,  2.03it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
            "Training:  13%|█▎        | 25/188 [00:13<01:54,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 24, Average Loss: 0.10284857296695311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|█▉        | 36/188 [00:18<01:13,  2.07it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
            "Training:  20%|█▉        | 37/188 [00:20<01:45,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 36, Average Loss: 0.09724414948787954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  26%|██▌       | 48/188 [00:25<01:08,  2.04it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Training:  26%|██▌       | 49/188 [00:26<01:38,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 48, Average Loss: 0.08980713423807174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|███▏      | 60/188 [00:32<01:02,  2.06it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "Training:  32%|███▏      | 61/188 [00:33<01:30,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 60, Average Loss: 0.08901137290522457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|███▊      | 72/188 [00:38<00:56,  2.06it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "Training:  39%|███▉      | 73/188 [00:40<01:21,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 72, Average Loss: 0.08279013517312706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  45%|████▍     | 84/188 [00:45<00:50,  2.07it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "Training:  45%|████▌     | 85/188 [00:46<01:17,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 84, Average Loss: 0.07887986778015536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  51%|█████     | 96/188 [00:52<00:43,  2.11it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
            "Training:  52%|█████▏    | 97/188 [00:53<01:02,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 96, Average Loss: 0.0755113614043997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  57%|█████▋    | 108/188 [00:58<00:38,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "Training:  58%|█████▊    | 109/188 [00:59<00:58,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 108, Average Loss: 0.07220608036516717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 120/188 [01:05<00:32,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
            "Training:  64%|██████▍   | 121/188 [01:06<00:46,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 120, Average Loss: 0.07003542224410922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|███████   | 132/188 [01:11<00:28,  1.99it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "Training:  71%|███████   | 133/188 [01:13<00:42,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 132, Average Loss: 0.06749784441975255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  77%|███████▋  | 144/188 [01:18<00:21,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Training:  77%|███████▋  | 145/188 [01:19<00:30,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 144, Average Loss: 0.06511638005678025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  83%|████████▎ | 156/188 [01:25<00:16,  1.99it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "Training:  84%|████████▎ | 157/188 [01:26<00:23,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 156, Average Loss: 0.06210045509326916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  89%|████████▉ | 168/188 [01:31<00:09,  2.04it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
            "Training:  90%|████████▉ | 169/188 [01:32<00:13,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 168, Average Loss: 0.05945617058092639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  96%|█████████▌| 180/188 [01:38<00:04,  1.92it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  96%|█████████▋| 181/188 [01:39<00:05,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 180, Average Loss: 0.05727709991236528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 189it [01:43,  1.82it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.057455620262771845, Accuracy: 0.9840, F1-Micro: 0.9840, F1-Macro: 0.9840\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|▋         | 12/188 [00:06<01:44,  1.69it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
            "Training:   7%|▋         | 13/188 [00:07<02:21,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 12, Average Loss: 0.03494974214117974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 24/188 [00:13<01:34,  1.73it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
            "Training:  13%|█▎        | 25/188 [00:15<02:09,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 24, Average Loss: 0.02999737433856353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|█▉        | 36/188 [00:21<01:28,  1.72it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  20%|█▉        | 37/188 [00:22<01:59,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 36, Average Loss: 0.029318796367281012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  26%|██▌       | 48/188 [00:28<01:10,  1.98it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "Training:  26%|██▌       | 49/188 [00:30<01:46,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 48, Average Loss: 0.027854498747425776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|███▏      | 60/188 [00:35<01:01,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
            "Training:  32%|███▏      | 61/188 [00:36<01:29,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 60, Average Loss: 0.028379089944064618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|███▊      | 72/188 [00:42<00:56,  2.04it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "Training:  39%|███▉      | 73/188 [00:43<01:27,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 72, Average Loss: 0.02737098566851475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  45%|████▍     | 84/188 [00:48<00:50,  2.04it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "Training:  45%|████▌     | 85/188 [00:50<01:14,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 84, Average Loss: 0.026952806100737126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  51%|█████     | 96/188 [00:55<00:46,  1.99it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "Training:  52%|█████▏    | 97/188 [00:56<01:08,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 96, Average Loss: 0.026789163564293023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  57%|█████▋    | 108/188 [01:02<00:38,  2.05it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
            "Training:  58%|█████▊    | 109/188 [01:03<00:55,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 108, Average Loss: 0.026466138932543497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 120/188 [01:08<00:34,  1.98it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "Training:  64%|██████▍   | 121/188 [01:10<00:50,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 120, Average Loss: 0.027067567404204358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|███████   | 132/188 [01:15<00:27,  2.06it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
            "Training:  71%|███████   | 133/188 [01:16<00:38,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 132, Average Loss: 0.0265423513377424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  77%|███████▋  | 144/188 [01:21<00:22,  1.92it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
            "Training:  77%|███████▋  | 145/188 [01:23<00:31,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 144, Average Loss: 0.025298087430807453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  83%|████████▎ | 156/188 [01:28<00:15,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Training:  84%|████████▎ | 157/188 [01:29<00:21,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 156, Average Loss: 0.024140635547108758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  89%|████████▉ | 168/188 [01:35<00:10,  1.95it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
            "Training:  90%|████████▉ | 169/188 [01:36<00:13,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 168, Average Loss: 0.0230429026095884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  96%|█████████▌| 180/188 [01:41<00:03,  2.03it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
            "Training:  96%|█████████▋| 181/188 [01:42<00:04,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 180, Average Loss: 0.022315445678153387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 189it [01:46,  1.76it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:08<00:00,  2.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.04391479461143414, Accuracy: 0.9873, F1-Micro: 0.9873, F1-Macro: 0.9873\n",
            "\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|▋         | 12/188 [00:05<01:23,  2.10it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
            "Training:   7%|▋         | 13/188 [00:06<02:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 12, Average Loss: 0.01283391008231168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 24/188 [00:12<01:20,  2.05it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
            "Training:  13%|█▎        | 25/188 [00:13<01:55,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 24, Average Loss: 0.012003667885437608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|█▉        | 36/188 [00:18<01:12,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "Training:  20%|█▉        | 37/188 [00:19<01:50,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 36, Average Loss: 0.011768512692975087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  26%|██▌       | 48/188 [00:25<01:16,  1.82it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
            "Training:  26%|██▌       | 49/188 [00:26<01:46,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 48, Average Loss: 0.0100122479974137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|███▏      | 60/188 [00:33<01:16,  1.68it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "Training:  32%|███▏      | 61/188 [00:34<01:47,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 60, Average Loss: 0.01017478978416572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|███▊      | 72/188 [00:40<01:07,  1.73it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
            "Training:  39%|███▉      | 73/188 [00:42<01:30,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 72, Average Loss: 0.010027940991373422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  45%|████▍     | 84/188 [00:48<00:57,  1.82it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
            "Training:  45%|████▌     | 85/188 [00:49<01:16,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 84, Average Loss: 0.010022284086084082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  51%|█████     | 96/188 [00:54<00:43,  2.10it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
            "Training:  52%|█████▏    | 97/188 [00:56<01:03,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 96, Average Loss: 0.010210671006158615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  57%|█████▋    | 108/188 [01:01<00:40,  2.00it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
            "Training:  58%|█████▊    | 109/188 [01:02<00:55,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 108, Average Loss: 0.009850375787613707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 120/188 [01:08<00:32,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
            "Training:  64%|██████▍   | 121/188 [01:09<00:46,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 120, Average Loss: 0.01041361420454147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|███████   | 132/188 [01:14<00:27,  2.07it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  71%|███████   | 133/188 [01:15<00:38,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 132, Average Loss: 0.010995526397671325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  77%|███████▋  | 144/188 [01:21<00:20,  2.10it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "Training:  77%|███████▋  | 145/188 [01:22<00:30,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 144, Average Loss: 0.010708128362441331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  83%|████████▎ | 156/188 [01:27<00:15,  2.09it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
            "Training:  84%|████████▎ | 157/188 [01:28<00:21,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 156, Average Loss: 0.010460052695961144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  89%|████████▉ | 168/188 [01:34<00:09,  2.11it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "Training:  90%|████████▉ | 169/188 [01:35<00:13,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 168, Average Loss: 0.010574371287865298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  96%|█████████▌| 180/188 [01:40<00:03,  2.07it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
            "Training:  96%|█████████▋| 181/188 [01:42<00:04,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 180, Average Loss: 0.010337831419504558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 189it [01:45,  1.78it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:08<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.03822938732143181, Accuracy: 0.9887, F1-Micro: 0.9887, F1-Macro: 0.9887\n",
            "\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|▋         | 12/188 [00:05<01:22,  2.14it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
            "Training:   7%|▋         | 13/188 [00:06<02:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 12, Average Loss: 0.005274776248067307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  13%|█▎        | 24/188 [00:11<01:21,  2.02it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "Training:  13%|█▎        | 25/188 [00:13<02:03,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 24, Average Loss: 0.005206687126095251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  19%|█▉        | 36/188 [00:18<01:13,  2.06it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
            "Training:  20%|█▉        | 37/188 [00:19<01:45,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 36, Average Loss: 0.004881543412921019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  26%|██▌       | 48/188 [00:25<01:11,  1.96it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
            "Training:  26%|██▌       | 49/188 [00:26<01:51,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 48, Average Loss: 0.004282085151013841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  32%|███▏      | 60/188 [00:31<01:02,  2.06it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Training:  32%|███▏      | 61/188 [00:32<01:30,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 60, Average Loss: 0.004340895924057501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  38%|███▊      | 72/188 [00:38<00:58,  1.97it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
            "Training:  39%|███▉      | 73/188 [00:39<01:24,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 72, Average Loss: 0.003921470897492125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  45%|████▍     | 84/188 [00:44<00:52,  2.00it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
            "Training:  45%|████▌     | 85/188 [00:46<01:15,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 84, Average Loss: 0.0036885419159218493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  51%|█████     | 96/188 [00:52<00:54,  1.68it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Training:  52%|█████▏    | 97/188 [00:53<01:14,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 96, Average Loss: 0.003604007610192639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  57%|█████▋    | 108/188 [01:00<00:45,  1.76it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
            "Training:  58%|█████▊    | 109/188 [01:01<01:03,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 108, Average Loss: 0.003417351145698275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 120/188 [01:07<00:39,  1.73it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
            "Training:  64%|██████▍   | 121/188 [01:09<00:56,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 120, Average Loss: 0.003406300622979567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|███████   | 132/188 [01:15<00:33,  1.67it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "Training:  71%|███████   | 133/188 [01:16<00:46,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 132, Average Loss: 0.0036919037875398344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  77%|███████▋  | 144/188 [01:23<00:24,  1.77it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
            "Training:  77%|███████▋  | 145/188 [01:24<00:33,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 144, Average Loss: 0.0036125098952955645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  83%|████████▎ | 156/188 [01:30<00:18,  1.72it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "Training:  84%|████████▎ | 157/188 [01:32<00:24,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 156, Average Loss: 0.003543402226708937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  89%|████████▉ | 168/188 [01:38<00:11,  1.77it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "Training:  90%|████████▉ | 169/188 [01:39<00:15,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 168, Average Loss: 0.0034618368377518243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  96%|█████████▌| 180/188 [01:45<00:04,  1.82it/s]\n",
            "Evaluationg batch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluationg batch: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
            "Training:  96%|█████████▋| 181/188 [01:47<00:05,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 180, Average Loss: 0.003508402625933134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 189it [01:51,  1.69it/s]\n",
            "Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.03397199074970558, Accuracy: 0.9897, F1-Micro: 0.9897, F1-Macro: 0.9897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация"
      ],
      "metadata": {
        "id": "C6vdl1LMf6xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D"
      ],
      "metadata": {
        "id": "ozGEF6m_btEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph_limits(features: np.ndarray) -> tuple:\n",
        "    x_lim = (\n",
        "        np.percentile(features[:, 0], 2.5),\n",
        "        np.percentile(features[:, 0], 97.5)\n",
        "    )\n",
        "    y_lim = (\n",
        "        np.percentile(features[:, 1], 2.5),\n",
        "        np.percentile(features[:, 1], 97.5)\n",
        "    )\n",
        "\n",
        "    x_margin = (x_lim[1] - x_lim[0]) * 0.05\n",
        "    y_margin = (y_lim[1] - y_lim[0]) * 0.05\n",
        "\n",
        "    result = (\n",
        "        (float(x_lim[0] - x_margin), float(x_lim[1] + x_margin)),\n",
        "        (float(y_lim[0] - y_margin), float(y_lim[1] + y_margin)),\n",
        "    )\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "KtFRSXwUfmVV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pca_before_1: list[np.ndarray, ...] = []\n",
        "all_pca_after_1: list[np.ndarray, ...] = []\n",
        "all_pca_before_2: list[np.ndarray, ...] = []\n",
        "all_pca_after_2: list[np.ndarray, ...] = []\n",
        "\n",
        "all_tsne_before_1: list[np.ndarray, ...] = []\n",
        "all_tsne_after_1: list[np.ndarray, ...] = []\n",
        "all_tsne_before_2: list[np.ndarray, ...] = []\n",
        "all_tsne_after_2: list[np.ndarray, ...] = []\n",
        "\n",
        "all_umap_before_1: list[np.ndarray, ...] = []\n",
        "all_umap_after_1: list[np.ndarray, ...] = []\n",
        "all_umap_before_2: list[np.ndarray, ...] = []\n",
        "all_umap_after_2: list[np.ndarray, ...] = []\n",
        "\n",
        "for epoch, nn_logs_epoch in tqdm(nn_logs.items()):\n",
        "    for iteration, nn_logs_iteration in nn_logs_epoch.items():\n",
        "        nn_before_1, nn_before_2, nn_after_2, nn_after_1, labels = nn_logs_iteration['nn_output']\n",
        "\n",
        "        scaler_before_1 = StandardScaler()\n",
        "        scaler_after_1 = StandardScaler()\n",
        "        nn_before_1 = scaler_before_1.fit_transform(nn_before_1)\n",
        "        nn_after_1 = scaler_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        scaler_before_2 = StandardScaler()\n",
        "        scaler_after_2 = StandardScaler()\n",
        "        nn_before_2 = scaler_before_2.fit_transform(nn_before_2)\n",
        "        nn_after_2 = scaler_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        # Transformers PCA\n",
        "        pca_transformer_before_1 = PCA(n_components=2)\n",
        "        pca_transformer_after_1 = PCA(n_components=2)\n",
        "        pca_before_1 = pca_transformer_before_1.fit_transform(nn_before_1)\n",
        "        pca_after_1 = pca_transformer_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        pca_transformer_before_2 = PCA(n_components=2)\n",
        "        pca_transformer_after_2 = PCA(n_components=2)\n",
        "        pca_before_2 = pca_transformer_before_2.fit_transform(nn_before_2)\n",
        "        pca_after_2 = pca_transformer_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        # Transformers t-SNE\n",
        "        tsne_transformer_before_1 = TSNE(n_components=2)\n",
        "        tsne_transformer_after_1 = TSNE(n_components=2)\n",
        "        tsne_before_1 = tsne_transformer_before_1.fit_transform(nn_before_1)\n",
        "        tsne_after_1 = tsne_transformer_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        tsne_transformer_before_2 = TSNE(n_components=2)\n",
        "        tsne_transformer_after_2 = TSNE(n_components=2)\n",
        "        tsne_before_2 = tsne_transformer_before_2.fit_transform(nn_before_2)\n",
        "        tsne_after_2 = tsne_transformer_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        # Transformers UMAP\n",
        "        umap_transformer_before_1 = umap.UMAP(n_components=2)\n",
        "        umap_transformer_after_1 = umap.UMAP(n_components=2)\n",
        "        umap_before_1 = umap_transformer_before_1.fit_transform(nn_before_1)\n",
        "        umap_after_1 = umap_transformer_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        umap_transformer_before_2 = umap.UMAP(n_components=2)\n",
        "        umap_transformer_after_2 = umap.UMAP(n_components=2)\n",
        "        umap_before_2 = umap_transformer_before_2.fit_transform(nn_before_2)\n",
        "        umap_after_2 = umap_transformer_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        all_pca_before_1.append(pca_before_1)\n",
        "        all_pca_after_1.append(pca_after_1)\n",
        "        all_pca_before_2.append(pca_before_2)\n",
        "        all_pca_after_2.append(pca_after_2)\n",
        "\n",
        "        all_tsne_before_1.append(tsne_before_1)\n",
        "        all_tsne_after_1.append(tsne_after_1)\n",
        "        all_tsne_before_2.append(tsne_before_2)\n",
        "        all_tsne_after_2.append(tsne_after_2)\n",
        "\n",
        "        all_umap_before_1.append(umap_before_1)\n",
        "        all_umap_after_1.append(umap_after_1)\n",
        "        all_umap_before_2.append(umap_before_2)\n",
        "        all_umap_after_2.append(umap_after_2)\n",
        "\n",
        "all_pca_before_1 = np.array(all_pca_before_1)\n",
        "all_pca_after_1 = np.array(all_pca_after_1)\n",
        "all_pca_before_2 = np.array(all_pca_before_2)\n",
        "all_pca_after_2 = np.array(all_pca_after_2)\n",
        "\n",
        "all_tsne_before_1 = np.array(all_tsne_before_1)\n",
        "all_tsne_after_1 = np.array(all_tsne_after_1)\n",
        "all_tsne_before_2 = np.array(all_tsne_before_2)\n",
        "all_tsne_after_2 = np.array(all_tsne_after_2)\n",
        "\n",
        "all_umap_before_1 = np.array(all_umap_before_1)\n",
        "all_umap_after_1 = np.array(all_umap_after_1)\n",
        "all_umap_before_2 = np.array(all_umap_before_2)\n",
        "all_umap_after_2 = np.array(all_umap_after_2)"
      ],
      "metadata": {
        "id": "T9u5fcIuVKt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_before, all_after = all_pca_before_1, all_pca_after_1"
      ],
      "metadata": {
        "id": "OBXThuuvUUGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_xlim_before, global_ylim_before = get_graph_limits(all_before.reshape(-1, 2))\n",
        "global_xlim_after, global_ylim_after = get_graph_limits(all_after.reshape(-1, 2))"
      ],
      "metadata": {
        "id": "qOW73DsaUQoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figures: list[go.Figure, ...] = []\n",
        "digits: list[int, ...] = list(map(str, range(0, 10)))\n",
        "n_iterations: int = len(train_loader)  # number of iterations in epoch\n",
        "iteration_step: int = 25  # step of iteration DON'T FORGET TO CHANGE THIS\n",
        "labels: np.ndarray[int, ...] = BALANCED_SAMPLE[1].cpu().numpy()\n",
        "\n",
        "for epoch, nn_logs_epoch in nn_logs.items():\n",
        "    for iteration, nn_logs_iteration in nn_logs_epoch.items():\n",
        "        # Get idx for pcas\n",
        "        idx = (epoch - 1) * (n_iterations - n_iterations % iteration_step) + iteration\n",
        "        idx //= iteration_step\n",
        "        idx -= 1\n",
        "\n",
        "        pca_before, pca_after = all_before[idx], all_after[idx]\n",
        "\n",
        "        df_before = pd.DataFrame(pca_before, columns=['Компонента 1', 'Компонента 2'])\n",
        "        df_before['Label'] = labels.astype(str)\n",
        "\n",
        "        df_after = pd.DataFrame(pca_after, columns=['Компонента 1', 'Компонента 2'])\n",
        "        df_after['Label'] = labels.astype(str)\n",
        "\n",
        "        fig = make_subplots(\n",
        "            rows=1,\n",
        "            cols=2,\n",
        "            subplot_titles=['Перед ДПФ (1)', 'После обратного ДПФ (4)']\n",
        "            # subplot_titles=['Перед комплексной основой (2)', 'После комплексной основы (3)']\n",
        "        )\n",
        "        tab10_colors = px.colors.qualitative.Dark24\n",
        "\n",
        "        for i, label in enumerate(digits):\n",
        "            df_subset_before = df_before[df_before['Label'] == label]\n",
        "            df_subset_after = df_after[df_after['Label'] == label]\n",
        "\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=df_subset_before['Компонента 1'],\n",
        "                y=df_subset_before['Компонента 2'],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=15,\n",
        "                    color=tab10_colors[i % len(tab10_colors)],\n",
        "                    opacity=1\n",
        "                ),\n",
        "                name=f'{label}',\n",
        "                showlegend=True\n",
        "            ), row=1, col=1)\n",
        "\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=df_subset_after['Компонента 1'],\n",
        "                y=df_subset_after['Компонента 2'],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=15,\n",
        "                    color=tab10_colors[i % len(tab10_colors)],\n",
        "                    opacity=1\n",
        "                ),\n",
        "                showlegend=False\n",
        "            ), row=1, col=2)\n",
        "\n",
        "        fig.update_layout(\n",
        "            xaxis_title='Компонента 1',\n",
        "            yaxis_title='Компонента 2',\n",
        "            xaxis2_title='Компонента 1',\n",
        "            yaxis2_title='Компонента 2',\n",
        "            legend_title='Common Legend',\n",
        "            legend=dict(\n",
        "                title='Цифры',\n",
        "                title_font_size=22,\n",
        "                font=dict(\n",
        "                    size=22,\n",
        "                ),  # Font size for the legend\n",
        "                traceorder='normal'\n",
        "            ),\n",
        "            width=1400,\n",
        "            height=700,\n",
        "        )\n",
        "\n",
        "        fig.update_xaxes(\n",
        "            range=global_xlim_before, title='Компонента 1',\n",
        "            tickfont=dict(size=18),\n",
        "            title_font=dict(size=20),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        fig.update_yaxes(\n",
        "            range=global_ylim_before,\n",
        "            title='Компонента 2',\n",
        "            tickfont=dict(size=18),\n",
        "            title_font=dict(size=20),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        fig.update_xaxes(\n",
        "            range=global_xlim_after,\n",
        "            title='Компонента 1',\n",
        "            tickfont=dict(size=18),\n",
        "            title_font=dict(size=20),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        fig.update_yaxes(\n",
        "            range=global_ylim_after,\n",
        "            title='Компонента 2',\n",
        "            tickfont=dict(size=18),\n",
        "            title_font=dict(size=20),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        fig.for_each_annotation(lambda a: a.update(font=dict(size=22)))\n",
        "\n",
        "        figures.append(fig)"
      ],
      "metadata": {
        "id": "I-kNmx6fNr8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3D"
      ],
      "metadata": {
        "id": "GwUCCtQbbo1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph_features_limits_3d(featuress: np.ndarray) -> tuple:\n",
        "    x_lim = (np.percentile(featuress[:, 0], 0.5), np.percentile(featuress[:, 0], 99.5))\n",
        "    y_lim = (np.percentile(featuress[:, 1], 0.5), np.percentile(featuress[:, 1], 99.5))\n",
        "    z_lim = (np.percentile(featuress[:, 2], 0.5), np.percentile(featuress[:, 2], 99.5))\n",
        "\n",
        "    x_margin = (x_lim[1] - x_lim[0]) * 0.05\n",
        "    y_margin = (y_lim[1] - y_lim[0]) * 0.05\n",
        "    z_margin = (z_lim[1] - z_lim[0]) * 0.05\n",
        "\n",
        "    result = (\n",
        "        (float(x_lim[0] - x_margin), float(x_lim[1] + x_margin)),\n",
        "        (float(y_lim[0] - y_margin), float(y_lim[1] + y_margin)),\n",
        "        (float(z_lim[0] - z_margin), float(z_lim[1] + z_margin))\n",
        "    )\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "wvSaS5O6WAej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pca_before_1: list[np.ndarray, ...] = []\n",
        "all_pca_after_1: list[np.ndarray, ...] = []\n",
        "all_pca_before_2: list[np.ndarray, ...] = []\n",
        "all_pca_after_2: list[np.ndarray, ...] = []\n",
        "\n",
        "all_tsne_before_1: list[np.ndarray, ...] = []\n",
        "all_tsne_after_1: list[np.ndarray, ...] = []\n",
        "all_tsne_before_2: list[np.ndarray, ...] = []\n",
        "all_tsne_after_2: list[np.ndarray, ...] = []\n",
        "\n",
        "all_umap_before_1: list[np.ndarray, ...] = []\n",
        "all_umap_after_1: list[np.ndarray, ...] = []\n",
        "all_umap_before_2: list[np.ndarray, ...] = []\n",
        "all_umap_after_2: list[np.ndarray, ...] = []\n",
        "\n",
        "for epoch, nn_logs_epoch in tqdm(nn_logs.items()):\n",
        "    for iteration, nn_logs_iteration in nn_logs_epoch.items():\n",
        "        # _, _, nn_before, nn_after, _ = nn_logs_iteration['nn_output']\n",
        "        nn_before_1, nn_before_2, nn_after_2, nn_after_1, labels = nn_logs_iteration['nn_output']\n",
        "\n",
        "        # 1\n",
        "        scaler_before_1 = StandardScaler()\n",
        "        scaler_after_1 = StandardScaler()\n",
        "        nn_before_1 = scaler_before_1.fit_transform(nn_before_1)\n",
        "        nn_after_1 = scaler_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        # 2\n",
        "        scaler_before_2 = StandardScaler()\n",
        "        scaler_after_2 = StandardScaler()\n",
        "        nn_before_2 = scaler_before_2.fit_transform(nn_before_2)\n",
        "        nn_after_2 = scaler_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        # Transformers PCA\n",
        "        # 1\n",
        "        pca_transformer_before_1 = PCA(n_components=3)\n",
        "        pca_transformer_after_1 = PCA(n_components=3)\n",
        "        pca_before_1 = pca_transformer_before_1.fit_transform(nn_before_1)\n",
        "        pca_after_1 = pca_transformer_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        # 2\n",
        "        pca_transformer_before_2 = PCA(n_components=3)\n",
        "        pca_transformer_after_2 = PCA(n_components=3)\n",
        "        pca_before_2 = pca_transformer_before_2.fit_transform(nn_before_2)\n",
        "        pca_after_2 = pca_transformer_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        # Transformers t-SNE\n",
        "        # 1\n",
        "        tsne_transformer_before_1 = TSNE(n_components=3)\n",
        "        tsne_transformer_after_1 = TSNE(n_components=3)\n",
        "        tsne_before_1 = tsne_transformer_before_1.fit_transform(nn_before_1)\n",
        "        tsne_after_1 = tsne_transformer_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        # 2\n",
        "        tsne_transformer_before_2 = TSNE(n_components=3)\n",
        "        tsne_transformer_after_2 = TSNE(n_components=3)\n",
        "        tsne_before_2 = tsne_transformer_before_2.fit_transform(nn_before_2)\n",
        "        tsne_after_2 = tsne_transformer_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        # Transformers UMAP\n",
        "        # 1\n",
        "        umap_transformer_before_1 = umap.UMAP(n_components=3)\n",
        "        umap_transformer_after_1 = umap.UMAP(n_components=3)\n",
        "        umap_before_1 = umap_transformer_before_1.fit_transform(nn_before_1)\n",
        "        umap_after_1 = umap_transformer_after_1.fit_transform(nn_after_1)\n",
        "\n",
        "        # 2\n",
        "        umap_transformer_before_2 = umap.UMAP(n_components=3)\n",
        "        umap_transformer_after_2 = umap.UMAP(n_components=3)\n",
        "        umap_before_2 = umap_transformer_before_2.fit_transform(nn_before_2)\n",
        "        umap_after_2 = umap_transformer_after_2.fit_transform(nn_after_2)\n",
        "\n",
        "        all_pca_before_1.append(pca_before_1)\n",
        "        all_pca_after_1.append(pca_after_1)\n",
        "        all_pca_before_2.append(pca_before_2)\n",
        "        all_pca_after_2.append(pca_after_2)\n",
        "\n",
        "        all_tsne_before_1.append(tsne_before_1)\n",
        "        all_tsne_after_1.append(tsne_after_1)\n",
        "        all_tsne_before_2.append(tsne_before_2)\n",
        "        all_tsne_after_2.append(tsne_after_2)\n",
        "\n",
        "        all_umap_before_1.append(umap_before_1)\n",
        "        all_umap_after_1.append(umap_after_1)\n",
        "        all_umap_before_2.append(umap_before_2)\n",
        "        all_umap_after_2.append(umap_after_2)\n",
        "\n",
        "all_pca_before_1 = np.array(all_pca_before_1)\n",
        "all_pca_after_1 = np.array(all_pca_after_1)\n",
        "all_pca_before_2 = np.array(all_pca_before_2)\n",
        "all_pca_after_2 = np.array(all_pca_after_2)\n",
        "\n",
        "all_tsne_before_1 = np.array(all_tsne_before_1)\n",
        "all_tsne_after_1 = np.array(all_tsne_after_1)\n",
        "all_tsne_before_2 = np.array(all_tsne_before_2)\n",
        "all_tsne_after_2 = np.array(all_tsne_after_2)\n",
        "\n",
        "all_umap_before_1 = np.array(all_umap_before_1)\n",
        "all_umap_after_1 = np.array(all_umap_after_1)\n",
        "all_umap_before_2 = np.array(all_umap_before_2)\n",
        "all_umap_after_2 = np.array(all_umap_after_2)"
      ],
      "metadata": {
        "id": "PrimlY9Kepsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_before, all_after = all_umap_before_2, all_umap_after_2"
      ],
      "metadata": {
        "id": "qDzSRgarrCzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_xlim_before, global_ylim_before, global_zlim_before = get_graph_features_limits_3d(all_before.reshape(-1, 3))\n",
        "global_xlim_after, global_ylim_after, global_zlim_after = get_graph_features_limits_3d(all_after.reshape(-1, 3))"
      ],
      "metadata": {
        "id": "9DO2vMbNyXXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_xlim_before"
      ],
      "metadata": {
        "id": "jhTPHYHs1RfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figures: list[go.Figure, ...] = []\n",
        "digits: list[int, ...] = list(map(str, range(0, 10)))\n",
        "n_iterations: int = len(train_loader)  # number of iterations in epoch\n",
        "iteration_step: int = 25  # step of iteration DON'T FORGET TO CHANGE THIS\n",
        "labels: np.ndarray[int, ...] = BALANCED_SAMPLE[1].cpu().numpy()\n",
        "\n",
        "\n",
        "for epoch, nn_logs_epoch in nn_logs.items():\n",
        "    for iteration, nn_logs_iteration in nn_logs_epoch.items():\n",
        "        # Get idx for pcas\n",
        "        idx = (epoch - 1) * (n_iterations - n_iterations % iteration_step) + iteration\n",
        "        idx //= iteration_step\n",
        "        idx -= 1\n",
        "\n",
        "        pca_before, pca_after = all_before[idx], all_after[idx]\n",
        "\n",
        "        df_before = pd.DataFrame(pca_before, columns=['Компонента 1', 'Компонента 2', 'Компонента 3'])\n",
        "        df_before['Label'] = labels.astype(str)\n",
        "\n",
        "        df_after = pd.DataFrame(pca_after, columns=['Компонента 1', 'Компонента 2', 'Компонента 3'])\n",
        "        df_after['Label'] = labels.astype(str)\n",
        "\n",
        "        fig = make_subplots(\n",
        "            rows=1,\n",
        "            cols=2,\n",
        "            horizontal_spacing=0.01,\n",
        "            specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
        "            # subplot_titles=['Перед ДПФ (1)', 'После обратного ДПФ (4)']\n",
        "            subplot_titles=['Перед комплексной основой (2)', 'После комплексной основы (3)']\n",
        "        )\n",
        "        tab10_colors = px.colors.qualitative.Dark24\n",
        "\n",
        "        for i, label in enumerate(digits):\n",
        "            df_subset_before = df_before[df_before['Label'] == label]\n",
        "            df_subset_after = df_after[df_after['Label'] == label]\n",
        "\n",
        "            fig.add_trace(go.Scatter3d(\n",
        "                x=df_subset_before['Компонента 1'],\n",
        "                y=df_subset_before['Компонента 2'],\n",
        "                z=df_subset_before['Компонента 3'],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=12,\n",
        "                    color=tab10_colors[i % len(tab10_colors)],\n",
        "                    opacity=1\n",
        "                ),\n",
        "                name=f'{label}',\n",
        "                showlegend=True\n",
        "            ), row=1, col=1)\n",
        "\n",
        "            # Add the second subplot (right)\n",
        "            fig.add_trace(go.Scatter3d(\n",
        "                x=df_subset_after['Компонента 1'],\n",
        "                y=df_subset_after['Компонента 2'],\n",
        "                z=df_subset_after['Компонента 3'],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=12,\n",
        "                    color=tab10_colors[i % len(tab10_colors)],\n",
        "                    opacity=1\n",
        "                ),\n",
        "                showlegend=False\n",
        "            ), row=1, col=2)\n",
        "\n",
        "        # Set layout with common legend and subplot titles\n",
        "        fig.update_layout(\n",
        "            scene=dict(\n",
        "                xaxis_title='Компонента 1',\n",
        "                yaxis_title='Компонента 2',\n",
        "                zaxis_title='Компонента 3',\n",
        "\n",
        "                xaxis_tickfont=dict(size=15),\n",
        "                yaxis_tickfont=dict(size=15),\n",
        "                zaxis_tickfont=dict(size=15),\n",
        "\n",
        "                xaxis_title_font=dict(size=20),\n",
        "                yaxis_title_font=dict(size=20),\n",
        "                zaxis_title_font=dict(size=20),\n",
        "\n",
        "                aspectmode='cube',\n",
        "            ),\n",
        "            scene2=dict(\n",
        "                aspectmode='cube',\n",
        "                xaxis_title='Компонента 1',\n",
        "                yaxis_title='Компонента 2',\n",
        "                zaxis_title='Компонента 3',\n",
        "\n",
        "                xaxis_tickfont=dict(size=15),\n",
        "                yaxis_tickfont=dict(size=15),\n",
        "                zaxis_tickfont=dict(size=15),\n",
        "\n",
        "                xaxis_title_font=dict(size=20),\n",
        "                yaxis_title_font=dict(size=20),\n",
        "                zaxis_title_font=dict(size=20),\n",
        "\n",
        "            ),\n",
        "            legend_title='Common Legend',\n",
        "            legend=dict(\n",
        "                title='Цифры',  # Common legend title\n",
        "                title_font_size=25,\n",
        "                font=dict(\n",
        "                    size=25,\n",
        "                ),  # Font size for the legend\n",
        "                traceorder='normal'\n",
        "            ),\n",
        "            width=1600,  # Width of the whole figure (larger to fit two plots)\n",
        "            height=800,  # Height of the whole figure\n",
        "        )\n",
        "\n",
        "        fig.for_each_annotation(lambda a: a.update(font=dict(size=24)))\n",
        "        figures.append(fig)"
      ],
      "metadata": {
        "id": "IfNL_spMcQvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figures[-1]"
      ],
      "metadata": {
        "id": "Nn1FZcbPsgTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестовые метрики"
      ],
      "metadata": {
        "id": "-xr2DdWS7ALC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiKzvk_5iw4v",
        "outputId": "c711efcf-3c90-4646-e75e-46e9e132223f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'avg_loss_train': 0.5143056427663628,\n",
              "  'mean_intra_distance_val': np.float64(0.02304094787687063),\n",
              "  'mean_inter_distance_val': np.float64(0.10502515695989131),\n",
              "  'avg_loss_val': 0.11277652019634843,\n",
              "  'accuracy_top1_val': 0.9666666666666667,\n",
              "  'f1_micro_val': 0.9666666666666667,\n",
              "  'f1_macro_val': 0.9669831070492554},\n",
              " 2: {'avg_loss_train': 0.056208513895089324,\n",
              "  'mean_intra_distance_val': np.float64(0.022554356418550015),\n",
              "  'mean_inter_distance_val': np.float64(0.11311280238959524),\n",
              "  'avg_loss_val': 0.057455620262771845,\n",
              "  'accuracy_top1_val': 0.984,\n",
              "  'f1_micro_val': 0.984,\n",
              "  'f1_macro_val': 0.9839772748313866},\n",
              " 3: {'avg_loss_train': 0.02187425231169711,\n",
              "  'mean_intra_distance_val': np.float64(0.022661614790558816),\n",
              "  'mean_inter_distance_val': np.float64(0.11949168261554506),\n",
              "  'avg_loss_val': 0.04391479461143414,\n",
              "  'accuracy_top1_val': 0.9873333333333333,\n",
              "  'f1_micro_val': 0.9873333333333333,\n",
              "  'f1_macro_val': 0.9873263876551015},\n",
              " 4: {'avg_loss_train': 0.010049007343192723,\n",
              "  'mean_intra_distance_val': np.float64(0.023213240690529345),\n",
              "  'mean_inter_distance_val': np.float64(0.12182606756687164),\n",
              "  'avg_loss_val': 0.03822938732143181,\n",
              "  'accuracy_top1_val': 0.9886666666666667,\n",
              "  'f1_micro_val': 0.9886666666666667,\n",
              "  'f1_macro_val': 0.9886580470049509},\n",
              " 5: {'avg_loss_train': 0.00344296358850849,\n",
              "  'mean_intra_distance_val': np.float64(0.023044449836015703),\n",
              "  'mean_inter_distance_val': np.float64(0.12432592196596993),\n",
              "  'avg_loss_val': 0.03397199074970558,\n",
              "  'accuracy_top1_val': 0.9896666666666667,\n",
              "  'f1_micro_val': 0.9896666666666667,\n",
              "  'f1_macro_val': 0.9896603829440778}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device);"
      ],
      "metadata": {
        "id": "Xi27M5VVj0KL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics, nn_test_logs, test_labels = evaluate_model(\n",
        "    model,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    device,\n",
        "    phase='Testing',\n",
        ")\n",
        "test_metrics = {key + '_test': val for key, val in test_metrics.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaJ2MVYt6cNE",
        "outputId": "3fa70e6d-cce4-4562-c22c-57ad0477038e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 24/24 [00:21<00:00,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results: Average Loss: 0.03360959488297036, Accuracy: 0.9880, F1-Micro: 0.9880, F1-Macro: 0.9880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inter_matrix, intra_matrix = compute_pairwise_distances(\n",
        "    np.array(nn_test_logs[4]),\n",
        "    np.array(test_labels),\n",
        "    10\n",
        ")\n",
        "dist_metrics = {\n",
        "    'mean_intra_distance_test': float(np.nanmean(intra_matrix)),\n",
        "    'mean_inter_distance_test': float(np.nanmean(inter_matrix[inter_matrix != 0]))\n",
        "}"
      ],
      "metadata": {
        "id": "QKDfrZF8rvTv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics.update(dist_metrics)"
      ],
      "metadata": {
        "id": "PuajABoJ7K1B"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssUYMIohr9G0",
        "outputId": "671250f6-2cd6-4739-8e24-abd293eb0b37"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_loss_test': 0.03360959488297036,\n",
              " 'accuracy_top1_test': 0.988,\n",
              " 'f1_micro_test': 0.988,\n",
              " 'f1_macro_test': 0.9879891609910763,\n",
              " 'mean_intra_distance_test': 0.023013068921864034,\n",
              " 'mean_inter_distance_test': 0.12449582285351224}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log(test_metrics)"
      ],
      "metadata": {
        "id": "bI1FJsXej73Y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "N9IFQ-eb7yVV",
        "outputId": "fb40d056-7f04-4900-b48e-b197365f31c1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_top1_test</td><td>▁</td></tr><tr><td>accuracy_top1_val</td><td>▁▆▇██</td></tr><tr><td>avg_batch_loss</td><td>█▅▅▅▄▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>avg_loss_test</td><td>▁</td></tr><tr><td>avg_loss_train</td><td>█▂▁▁▁</td></tr><tr><td>avg_loss_val</td><td>█▃▂▁▁</td></tr><tr><td>f1_macro_test</td><td>▁</td></tr><tr><td>f1_macro_val</td><td>▁▆▇██</td></tr><tr><td>f1_micro_test</td><td>▁</td></tr><tr><td>f1_micro_val</td><td>▁▆▇██</td></tr><tr><td>mean_inter_distance_test</td><td>▁</td></tr><tr><td>mean_inter_distance_val</td><td>▁▄▆▇█</td></tr><tr><td>mean_intra_distance_test</td><td>▁</td></tr><tr><td>mean_intra_distance_val</td><td>▆▁▂█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_top1_test</td><td>0.988</td></tr><tr><td>accuracy_top1_val</td><td>0.98967</td></tr><tr><td>avg_batch_loss</td><td>0.00351</td></tr><tr><td>avg_loss_test</td><td>0.03361</td></tr><tr><td>avg_loss_train</td><td>0.00344</td></tr><tr><td>avg_loss_val</td><td>0.03397</td></tr><tr><td>f1_macro_test</td><td>0.98799</td></tr><tr><td>f1_macro_val</td><td>0.98966</td></tr><tr><td>f1_micro_test</td><td>0.988</td></tr><tr><td>f1_micro_val</td><td>0.98967</td></tr><tr><td>mean_inter_distance_test</td><td>0.1245</td></tr><tr><td>mean_inter_distance_val</td><td>0.12433</td></tr><tr><td>mean_intra_distance_test</td><td>0.02301</td></tr><tr><td>mean_intra_distance_val</td><td>0.02304</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">complex_bs_128_lr_3e-05</strong> at: <a href='https://wandb.ai/aelyovin/AudioMNIST/runs/hcoumbfq' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST/runs/hcoumbfq</a><br> View project at: <a href='https://wandb.ai/aelyovin/AudioMNIST' target=\"_blank\">https://wandb.ai/aelyovin/AudioMNIST</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250708_154344-hcoumbfq/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}